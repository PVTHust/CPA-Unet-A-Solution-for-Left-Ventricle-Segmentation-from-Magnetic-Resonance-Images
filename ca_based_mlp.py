# -*- coding: utf-8 -*-
"""CA_based_MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ps8JPX8OwQqo0NTsEXP46n5s0DeN7GMV
"""

class ChannelPool(nn.Module):
    def __init__(self):
      super(ChannelPool,self).__init__()
    def forward(self, x):
        return torch.cat( [torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)], dim=1 )

class Context_attention(nn.Module):
  def __init__(self,c_in,in_channel,ksize=5):
    super(Context_attention,self).__init__()
    self.adaptive_avg = nn.AdaptiveAvgPool2d(1)
    self.adaptive_max = nn.AdaptiveMaxPool2d(1)
    self.fc = nn.Sequential(
            nn.Linear(c_in, c_in // 8, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(c_in // 8, c_in, bias=False),
            nn.Sigmoid(),
        )
    self.channel_conv = nn.Conv1d(1,1,kernel_size = ksize,padding = ksize//2)
    self.conv_3x3 = nn.Conv2d(c_in,c_in,kernel_size=3,padding=1,stride=1)
    self.compress = ChannelPool()
    self.conv =nn.Sequential(
        nn.Conv2d(2,1,kernel_size=1,padding=0),
        nn.Sigmoid())
    self.out_layer = nn.Conv2d(3*c_in,in_channel,kernel_size=1,padding=0)

  def forward(self,x):
    #Channel attention
    b,c,h,w = x.shape
    x1 = self.adaptive_avg(x)
    x1 = x1.view(x1.size(0), -1)
    x1 = self.fc(x1).view(b, c, 1, 1)
    x1 = x*x1
    x2 = self.adaptive_max(x)
    x2 = x2.view(x2.size(0), -1)
    x2 = self.fc(x2).view(b, c, 1, 1)
    x2 = x*x2
    out_channel = x1+x2
    #Convolution
    out_conv    = self.conv_3x3(x)
    #Spatial attention
    out_spatial = self.compress(x)
    out_spatial = self.conv(out_spatial) * x

    out1 = out_conv * out_channel
    out2 = out_conv * out_spatial
    out  = torch.cat([out1,out2,x],dim=1)
    out  = self.out_layer(out)
    return out