# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ps8JPX8OwQqo0NTsEXP46n5s0DeN7GMV
"""

w = [32, 64, 128, 256,512]
class CPA_Unet(nn.Module):
    def __init__(self, initial_channels, num_classes):
        # Encoder layers
        super(CPA_Unet, self).__init__()
        self.dc_block1 = DenseBlock(initial_channels,5,11,16,w[0])

        self.dc_block2 = nn.Sequential(
            Pooling_attention(w[0]),
            DenseBlock(w[0],11,21,32,w[1]))

        self.dc_block3 = nn.Sequential(
            Pooling_attention(w[1]),
            DenseBlock(w[1],21,43,64,w[2])
           )

        self.dc_block4 = nn.Sequential(
            Pooling_attention(w[2]),
            DenseBlock(w[2],43,85, 128, w[3])
            )

        self.bridge = nn.Sequential(
            Pooling_attention(w[3]),
            PASPP(w[3],w[3]),
            Upsample_(2),
            nn.BatchNorm2d(w[3]),
            nn.ReLU()
            )
        # Decoder Layers
        self.dc_block5 = nn.Sequential(
            DenseBlock(w[3],21,43,64,w[2]),
            Upsample_(2),
            nn.BatchNorm2d(w[2]),
            nn.ReLU()
        )
        self.dc_block6 = nn.Sequential(
            DenseBlock(w[2],11,21,32,w[1]),
            Upsample_(2),
            nn.BatchNorm2d(w[1]),
            nn.ReLU()
            )
        self.dc_block7 = nn.Sequential(
            DenseBlock(w[1],5,11,16,w[0]),
            Upsample_(2),
            nn.BatchNorm2d(w[0]),
            nn.ReLU()
        )
        self.dc_block8 = nn.Sequential(
            DenseBlock(w[0],5,11,16,w[0]),
        )
        self.up1 = Upsample_(4)
        self.up2 = Upsample_(2)
        self.up3 = Upsample_(1)

        # CA Path
        self.ca4 = Context_attention(w[4],w[3])
        self.ca3 = Context_attention(w[3],w[2])
        self.ca2 = Context_attention(w[2],w[1])
        self.ca1 = Context_attention(w[1],w[0])
        # Final layer
        self.final_layer = nn.Sequential(nn.Conv2d(w[3],1,kernel_size=1,padding=0),
                                         nn.Sigmoid())
    def forward(self, x):
        # Encoder
        h1 = self.dc_block1(x)

        h2 = self.dc_block2(h1)

        h3 = self.dc_block3(h2)

        h4 = self.dc_block4(h3)

        h = self.bridge(h4)

        # # Decoder
        h = torch.cat([h,h4],dim=1)
        h = self.ca4(h)
        h = self.dc_block5(h)
        d1= self.up1(h)

        h = torch.cat([h,h3],dim=1)
        h = self.ca3(h)
        h = self.dc_block6(h)
        d2 = self.up2(h)

        h = torch.cat([h,h2],dim=1)
        h = self.ca2(h)
        h = self.dc_block7(h)
        d3=self.up3(h)

        h = torch.cat([h,h1],dim=1)
        h = self.ca1(h)
        h = self.dc_block8(h)

        h = torch.cat([d1,d2,d3,h],dim=1)
        # Output
        return self.final_layer(h)